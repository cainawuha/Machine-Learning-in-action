                                 pros                                                                               cons
KNN                    high accuracy, insensitive to outliers,no assumptions about data             computationally expensive, require a lot of memory
decision trees         computationally cheap, easy for humans to understand learned results,        prone to overfitting
                       can deal with irrelevant features   
naive Bayes            works with small amount of data, handles multiple classes                    sensitive tp how input data is prepared          
logistic regression    Computationally inexpensive, easy to implement, knowledge representation     Prone to underfitting, may have low accuracy
                       easy to interpret
SVM                    low generalization error, computationally inexpensive,                       sensitive to tuning parameters and kernel choice,
                       easy to interpret results                                                    only handle binary classification
